{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Stop Word List from Monolingual Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First import preprocesser and clean the data\n",
    "# we will use the Masakhane Preprocessor.\n",
    "from preprocess import Preprocessor\n",
    "\n",
    "my_prep = Preprocessor(lang='am', strip_punctuation=True, strip_symbols=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "def get_monolingual_data(path):\n",
    "    \"\"\"\n",
    "    A function to get read the monolingal data in the provided path. \n",
    "\n",
    "    Param: \n",
    "    path: the path to the monolingual data\n",
    "\n",
    "    Returns:\n",
    "    corpus: a list of strings of each of the text read from the monolingual files.     \n",
    "    \n",
    "    \"\"\"\n",
    "    corpus=[]\n",
    "    for root, dir, files in os.walk(path):\n",
    "        corpus=[]\n",
    "        for file in files:\n",
    "            corpus.append(open(os.path.join(root,file), 'r').read())\n",
    "    return corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will then call the baove function by providing the path to our data.\n",
    "corpus=get_monolingual_data('/home/hellina/NLP/Tools/corpra/am')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will now create a dataframe to hold the monolingual data and we will populate the other columns through the notebook.\n",
    "corpra_df=pd.DataFrame(columns=['Text', 'Clean Text', 'Words', 'Top Words'])\n",
    "corpra_df[\"Text\"]=corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Clean Text</th>\n",
       "      <th>Words</th>\n",
       "      <th>Top Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>የዚህ ስብሰባ አጣዳፊነት በእስራኤላውያንም ሆነ በፍልስጤማውያን ላይ የትላ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ከኤሊምም ተጓዙ፥ የእስራኤልም ልጆች ማኅበር ሁሉ ከግብፅ አገር ከወጡ በኋ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>የመጣጥፉም መዳረሻ ይሄ ነው። \\nነብሷን ይማረው እና ወላጅ እናቴ ከአቅሟ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>የኢትዮጵያ ፌደራላዊ ዲሞክራሲያዊ ሪፐብሊክ ፌደራል ነጋሪት ጋዜጣ\\nሃያ ሁ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>በእግዚአብሔር ፈቃድ የኢየሱስ ክርስቶስ ሐዋርያ ሊሆን የተጠራ ጳውሎስ ወን...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>መቅድም\\nይህ “የአፍሪካ አልማናክ” ተብሎ የተሰየመው መጽሐፍ ሰዚሀ ዐይነ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text Clean Text Words  \\\n",
       "0  የዚህ ስብሰባ አጣዳፊነት በእስራኤላውያንም ሆነ በፍልስጤማውያን ላይ የትላ...        NaN   NaN   \n",
       "1  ከኤሊምም ተጓዙ፥ የእስራኤልም ልጆች ማኅበር ሁሉ ከግብፅ አገር ከወጡ በኋ...        NaN   NaN   \n",
       "2  የመጣጥፉም መዳረሻ ይሄ ነው። \\nነብሷን ይማረው እና ወላጅ እናቴ ከአቅሟ...        NaN   NaN   \n",
       "3  የኢትዮጵያ ፌደራላዊ ዲሞክራሲያዊ ሪፐብሊክ ፌደራል ነጋሪት ጋዜጣ\\nሃያ ሁ...        NaN   NaN   \n",
       "4  በእግዚአብሔር ፈቃድ የኢየሱስ ክርስቶስ ሐዋርያ ሊሆን የተጠራ ጳውሎስ ወን...        NaN   NaN   \n",
       "5  መቅድም\\nይህ “የአፍሪካ አልማናክ” ተብሎ የተሰየመው መጽሐፍ ሰዚሀ ዐይነ...        NaN   NaN   \n",
       "\n",
       "  Top Words  \n",
       "0       NaN  \n",
       "1       NaN  \n",
       "2       NaN  \n",
       "3       NaN  \n",
       "4       NaN  \n",
       "5       NaN  "
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpra_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "def get_top_words(word_list, num):\n",
    "    \"\"\"\n",
    "    A function to get the top frequent n words in the word list. \n",
    "\n",
    "    Param:\n",
    "    word_list: a list of words from our monolingual data.\n",
    "    num: the number of top words we would like to return.\n",
    "\n",
    "    Return:\n",
    "    A list of tuples with the top n words and their corresponding frequency.\n",
    "    \n",
    "    \"\"\"\n",
    "    counter=Counter(word_list, sorted=True)\n",
    "    return counter.most_common(num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc(text):\n",
    "    \"\"\"\n",
    "    A function to remove the new line characther and preprocess our text data.\n",
    "    \n",
    "    Params:\n",
    "    text: the text we want to clean\n",
    "    \n",
    "    Returns:\n",
    "    Cleaned and preprocessed string.\n",
    "\n",
    "    \"\"\"\n",
    "    text= re.sub('\\\\n', \" \", text)\n",
    "    return my_prep.preprocess_str(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will now use the apply function and call the above functions on the appropriate columns in the dataframe. \n",
    "# we start by calling the preproc function on the text we read from our files. \n",
    "\n",
    "corpra_df[\"Clean Text\"]=corpra_df['Text'].apply(lambda text: preproc(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next we will convert the strings into individual words. \n",
    "# The split is done based on space. Pass the appropriate demaracation to the split function if your data requries it.\n",
    "corpra_df['Words']=corpra_df['Clean Text'].apply(lambda text: text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will now call the get_top_words function to get the top words in each of our files. \n",
    "corpra_df['Top Words']=corpra_df['Words'].apply(lambda top_word: get_top_words(top_word, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Clean Text</th>\n",
       "      <th>Words</th>\n",
       "      <th>Top Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>የዚህ ስብሰባ አጣዳፊነት በእስራኤላውያንም ሆነ በፍልስጤማውያን ላይ የትላ...</td>\n",
       "      <td>የዚህ ስብሰባ አጣዳፊነት በእስራኤላውያንም ሆነ በፍልስጤማውያን ላይ የትላ...</td>\n",
       "      <td>[የዚህ, ስብሰባ, አጣዳፊነት, በእስራኤላውያንም, ሆነ, በፍልስጤማውያን,...</td>\n",
       "      <td>[(ላይ, 932), (ነው, 894), (ውስጥ, 860), (ነበር, 666),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ከኤሊምም ተጓዙ፥ የእስራኤልም ልጆች ማኅበር ሁሉ ከግብፅ አገር ከወጡ በኋ...</td>\n",
       "      <td>ከኤሊምም ተጓዙ የእስራኤልም ልጆች ማኅበር ሁሉ ከግብፅ አገር ከወጡ በኋላ...</td>\n",
       "      <td>[ከኤሊምም, ተጓዙ, የእስራኤልም, ልጆች, ማኅበር, ሁሉ, ከግብፅ, አገር...</td>\n",
       "      <td>[(ወደ, 9064), (ላይ, 9029), (ሁሉ, 8052), (ነው, 7210...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>የመጣጥፉም መዳረሻ ይሄ ነው። \\nነብሷን ይማረው እና ወላጅ እናቴ ከአቅሟ...</td>\n",
       "      <td>የመጣጥፉም መዳረሻ ይሄ ነው ነብሷን ይማረው እና ወላጅ እናቴ ከአቅሟ በላ...</td>\n",
       "      <td>[የመጣጥፉም, መዳረሻ, ይሄ, ነው, ነብሷን, ይማረው, እና, ወላጅ, እና...</td>\n",
       "      <td>[(ነው, 14134), (እና, 13474), (ላይ, 9999), (ውስጥ, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>የኢትዮጵያ ፌደራላዊ ዲሞክራሲያዊ ሪፐብሊክ ፌደራል ነጋሪት ጋዜጣ\\nሃያ ሁ...</td>\n",
       "      <td>የኢትዮጵያ ፌደራላዊ ዲሞክራሲያዊ ሪፐብሊክ ፌደራል ነጋሪት ጋዜጣ ሃያ ሁለ...</td>\n",
       "      <td>[የኢትዮጵያ, ፌደራላዊ, ዲሞክራሲያዊ, ሪፐብሊክ, ፌደራል, ነጋሪት, ጋዜ...</td>\n",
       "      <td>[(ወይም, 1530), (እና, 1061), (ላይ, 883), (አዋጅ, 791...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>በእግዚአብሔር ፈቃድ የኢየሱስ ክርስቶስ ሐዋርያ ሊሆን የተጠራ ጳውሎስ ወን...</td>\n",
       "      <td>በእግዚአብሔር ፈቃድ የኢየሱስ ክርስቶስ ሐዋርያ ሊሆን የተጠራ ጳውሎስ ወን...</td>\n",
       "      <td>[በእግዚአብሔር, ፈቃድ, የኢየሱስ, ክርስቶስ, ሐዋርያ, ሊሆን, የተጠራ,...</td>\n",
       "      <td>[(ወደ, 1316), (ግን, 1194), (ሁሉ, 904), (እንደ, 810)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>መቅድም\\nይህ “የአፍሪካ አልማናክ” ተብሎ የተሰየመው መጽሐፍ ሰዚሀ ዐይነ...</td>\n",
       "      <td>መቅድም ይህ የአፍሪካ አልማናክ ተብሎ የተሰየመው መጽሐፍ ሰዚሀ ዐይነት ሲ...</td>\n",
       "      <td>[መቅድም, ይህ, የአፍሪካ, አልማናክ, ተብሎ, የተሰየመው, መጽሐፍ, ሰዚ...</td>\n",
       "      <td>[(ዓም, 505), (ነው, 283), (ቀን, 227), (ምክር, 197), ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  የዚህ ስብሰባ አጣዳፊነት በእስራኤላውያንም ሆነ በፍልስጤማውያን ላይ የትላ...   \n",
       "1  ከኤሊምም ተጓዙ፥ የእስራኤልም ልጆች ማኅበር ሁሉ ከግብፅ አገር ከወጡ በኋ...   \n",
       "2  የመጣጥፉም መዳረሻ ይሄ ነው። \\nነብሷን ይማረው እና ወላጅ እናቴ ከአቅሟ...   \n",
       "3  የኢትዮጵያ ፌደራላዊ ዲሞክራሲያዊ ሪፐብሊክ ፌደራል ነጋሪት ጋዜጣ\\nሃያ ሁ...   \n",
       "4  በእግዚአብሔር ፈቃድ የኢየሱስ ክርስቶስ ሐዋርያ ሊሆን የተጠራ ጳውሎስ ወን...   \n",
       "5  መቅድም\\nይህ “የአፍሪካ አልማናክ” ተብሎ የተሰየመው መጽሐፍ ሰዚሀ ዐይነ...   \n",
       "\n",
       "                                          Clean Text  \\\n",
       "0  የዚህ ስብሰባ አጣዳፊነት በእስራኤላውያንም ሆነ በፍልስጤማውያን ላይ የትላ...   \n",
       "1  ከኤሊምም ተጓዙ የእስራኤልም ልጆች ማኅበር ሁሉ ከግብፅ አገር ከወጡ በኋላ...   \n",
       "2  የመጣጥፉም መዳረሻ ይሄ ነው ነብሷን ይማረው እና ወላጅ እናቴ ከአቅሟ በላ...   \n",
       "3  የኢትዮጵያ ፌደራላዊ ዲሞክራሲያዊ ሪፐብሊክ ፌደራል ነጋሪት ጋዜጣ ሃያ ሁለ...   \n",
       "4  በእግዚአብሔር ፈቃድ የኢየሱስ ክርስቶስ ሐዋርያ ሊሆን የተጠራ ጳውሎስ ወን...   \n",
       "5  መቅድም ይህ የአፍሪካ አልማናክ ተብሎ የተሰየመው መጽሐፍ ሰዚሀ ዐይነት ሲ...   \n",
       "\n",
       "                                               Words  \\\n",
       "0  [የዚህ, ስብሰባ, አጣዳፊነት, በእስራኤላውያንም, ሆነ, በፍልስጤማውያን,...   \n",
       "1  [ከኤሊምም, ተጓዙ, የእስራኤልም, ልጆች, ማኅበር, ሁሉ, ከግብፅ, አገር...   \n",
       "2  [የመጣጥፉም, መዳረሻ, ይሄ, ነው, ነብሷን, ይማረው, እና, ወላጅ, እና...   \n",
       "3  [የኢትዮጵያ, ፌደራላዊ, ዲሞክራሲያዊ, ሪፐብሊክ, ፌደራል, ነጋሪት, ጋዜ...   \n",
       "4  [በእግዚአብሔር, ፈቃድ, የኢየሱስ, ክርስቶስ, ሐዋርያ, ሊሆን, የተጠራ,...   \n",
       "5  [መቅድም, ይህ, የአፍሪካ, አልማናክ, ተብሎ, የተሰየመው, መጽሐፍ, ሰዚ...   \n",
       "\n",
       "                                           Top Words  \n",
       "0  [(ላይ, 932), (ነው, 894), (ውስጥ, 860), (ነበር, 666),...  \n",
       "1  [(ወደ, 9064), (ላይ, 9029), (ሁሉ, 8052), (ነው, 7210...  \n",
       "2  [(ነው, 14134), (እና, 13474), (ላይ, 9999), (ውስጥ, 5...  \n",
       "3  [(ወይም, 1530), (እና, 1061), (ላይ, 883), (አዋጅ, 791...  \n",
       "4  [(ወደ, 1316), (ግን, 1194), (ሁሉ, 904), (እንደ, 810)...  \n",
       "5  [(ዓም, 505), (ነው, 283), (ቀን, 227), (ምክር, 197), ...  "
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpra_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the top words in each file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import font_manager\n",
    "# if matplotlib supports your languges' font, comment out the following section.\n",
    "# if it does not support your font, change the font path to the path of your font and change the name in the FontEntry function.\n",
    "\n",
    "font_path= '/home/hellina/Downloads/AbyssinicaSIL-Regular.ttf'\n",
    "font_entry= font_manager.FontEntry(fname=font_path, name='Abyssinica-SIL')\n",
    "font_manager.fontManager.ttflist.insert(0, font_entry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_top_words(top_words, num=10):\n",
    "    \"\"\"\n",
    "    Bar plots of the top words in each of the text files.\n",
    "\n",
    "    Params:\n",
    "    top_words: a list of top words we would like to visualize. It is a list of tuples of the top words and their frequency. \n",
    "    num: the number of top words we are interested in visualizing from the list.\n",
    "    \"\"\"\n",
    "    x=[ i[0] for i in top_words[:num]]\n",
    "    y=[j[1] for j in top_words[:num]]\n",
    "\n",
    "    plt.bar(x,y)\n",
    "    plt.rcParams['font.family']= font_entry.name # comment this out if your font is supported by matplotlib\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_top_words(corpra_df['Top Words'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_top_words(corpra_df['Top Words'][1], 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_vectorize(preprocessor):\n",
    "    \"\"\"\n",
    "    Use Sklearn tfidf vectorizer to transform the text to TF-IDF vectorized format. \n",
    "    \n",
    "    Param:\n",
    "    preprocessor: the preprocessor we are using. \n",
    "\n",
    "    Returns:\n",
    "    The vocabulary.\n",
    "    A list of stop words, if any, that qualify under sklearn stopword rules.\n",
    "    The IDF values of each of the words. \n",
    "\n",
    "    \"\"\"\n",
    "    vectorizer=TfidfVectorizer(preprocessor=preprocessor)\n",
    "    vectorizer.fit_transform(corpra_df['Clean Text'])\n",
    "\n",
    "    return vectorizer.vocabulary_, vectorizer.stop_words_, vectorizer.idf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab, stop_list, idf= tfidf_vectorize(preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words in the vocabulary is:  202604\n"
     ]
    }
   ],
   "source": [
    "print('Total number of words in the vocabulary is: ', len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "561"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this will give us the indices of words that are found in all of the files. \n",
    "indexes=[i for i, id in enumerate(idf) if id==1]\n",
    "stop_list=[word for word, index in vocab.items() if index in indexes]\n",
    "len(stop_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_top_words(stop_list, top_words):\n",
    "    \"\"\"\n",
    "    From the list of words that exist in each of the documents, we can further filter our list by selecting words that are in the top words list of the documents.\n",
    "    \n",
    "    Params:\n",
    "    stop_list: list of words found in every document.\n",
    "    top_words: Series object with list of tuples of top words and their frequency for each document.\n",
    "\n",
    "    Returns:\n",
    "    stop_words: words that are found in all the documents and in the top words.\n",
    "    \"\"\"\n",
    "    top_word=[]\n",
    "    for top in top_words:\n",
    "        top_word.append([x[0] for x in top])\n",
    "    top_word=[sub  for main in top_word for sub in main ]\n",
    "    stop_words=[k for k in set(stop_list).intersection(set(top_word))]\n",
    "    return stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words=match_top_words(stop_list, corpra_df['Top Words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(stop_list, stop_words):\n",
    "    \"\"\"\n",
    "    Saves the stop_list and the filtered stop_words.\n",
    "\n",
    "    Params:\n",
    "    stop_list: list of words in every document.\n",
    "    stop_words: list of words in every document as well as top words list.\n",
    "    \"\"\"\n",
    "    with open('stop_list_all_files.txt', 'w') as file:\n",
    "        file.write('\\n'.join(stop_list)) \n",
    "        file.close()\n",
    "    with open('stop_list_top_word.txt', 'w') as file:\n",
    "        file.write('\\n'.join(stop_words))\n",
    "        file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(stop_list, stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_top_words(top_words):\n",
    "    \"\"\"\n",
    "    Save individual documents most frequent words if necessary. Can be used as domain specific stop_words.append\n",
    "\n",
    "    Params:\n",
    "    top_words: list of tupels of top words in a document along with their frequency. \n",
    "    \"\"\"\n",
    "    top_word=[x[0] for x in top_words]\n",
    "    with open('top_words.txt', 'w') as file:\n",
    "        file.write('\\n'.join(top_word))\n",
    "        file.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_top_words(corpra_df['Top Words'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare with existing stopword list\n",
    "def compare(path, stop_list):\n",
    "    \"\"\"\n",
    "    Compare the stop words we have curated with an existing list.append\n",
    "\n",
    "    Params:\n",
    "    path: path to the file with a list of stop words.\n",
    "\n",
    "    Returns:\n",
    "    common_words: stop words found in common with the ones we have curated.\n",
    "    diff_words: stop words that are only found in the list we are trying to compare with. \n",
    "    \"\"\"\n",
    "    stop_compare=open(path, 'r').read()\n",
    "    stop_compare=set(preproc(stop_compare).split())\n",
    "    print('Number of stop words in list: ' ,len(stop_compare))\n",
    "    print('Number of stop words identified: ' ,len(stop_list))\n",
    "    common_words = stop_compare.intersection(set(stop_list))\n",
    "    diff_words=  stop_compare - set(stop_list)\n",
    "    print('There are ', len(common_words), ' common stopwords')\n",
    "    print('There are ', len(diff_words), ' non common words')\n",
    "    return common_words, diff_words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stop words in list:  302\n",
      "Number of stop words identified:  143\n",
      "There are  70  common stopwords\n",
      "There are  232  non common words\n"
     ]
    }
   ],
   "source": [
    "comm, diff =compare('stopwords.txt', stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ምን', 'ሆኖ', 'አሁን', 'ብቻ', 'እኔ', 'ሆኑ', 'ቢሆን', 'ቦታ', 'ነገሮች', 'ሆኖም', 'ሌላ', 'ላይ', 'ብሎ', 'ሰው', 'ከሆነ', 'ይህ', 'ይህን', 'በላይ', 'ሰዎች', 'ይሁን', 'አንድ', 'ቁጥር', 'ከተማ', 'ወይም', 'ነው', 'ቀን', 'ማድረግ', 'ጊዜ', 'መልካም', 'ዋና', 'ፊት', 'ሲሉ', 'ምክንያት', 'ልጅ', 'ሲል', 'ድረስ', 'ይሆናል', 'እንጂ', 'ያለ', 'ብዙ', 'አይደለም', 'ጉዳይ', 'ደግሞ', 'ስለ', 'ሁሉ', 'ምንም', 'ቤት', 'ይችላል', 'ብዛት', 'እንደ', 'እንዲሁም', 'ክፍል', 'መካከል', 'በኋላ', 'ናቸው', 'ሆነ', 'ግን', 'ጋር', 'ወደ', 'ማለት', 'በዚህ', 'ሲሆን', 'እስከ', 'በፊት', 'ስራ', 'ያለው', 'ነገር', 'ሌሎች', 'ውስጥ', 'ስም'}\n"
     ]
    }
   ],
   "source": [
    "print(comm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3e50f285cda5c82fceacb52d49d584f85b5af56fdb773c75edf23b3aee51f9e9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
